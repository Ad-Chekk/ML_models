{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ad-Chekk/ML_models/blob/main/fake_news_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7ea12c31",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "papermill": {
          "duration": 3.304096,
          "end_time": "2024-03-31T17:35:00.991840",
          "exception": false,
          "start_time": "2024-03-31T17:34:57.687744",
          "status": "completed"
        },
        "tags": [],
        "id": "7ea12c31"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import regex as re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8d0818e8",
      "metadata": {
        "papermill": {
          "duration": 4.402841,
          "end_time": "2024-03-31T17:35:05.409074",
          "exception": false,
          "start_time": "2024-03-31T17:35:01.006233",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "8d0818e8",
        "outputId": "acd1beb4-4613-4332-ee36-c2198a2b322a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'True.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0bb899edd317>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"True.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fake.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'True.csv'"
          ]
        }
      ],
      "source": [
        "real = pd.read_csv(\"True.csv\")\n",
        "fake = pd.read_csv(\"Fake.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a71ca78",
      "metadata": {
        "papermill": {
          "duration": 0.014999,
          "end_time": "2024-03-31T17:35:05.438017",
          "exception": false,
          "start_time": "2024-03-31T17:35:05.423018",
          "status": "completed"
        },
        "tags": [],
        "id": "7a71ca78"
      },
      "source": [
        "**Let's start by first adding the target value to our real and fake news as 1 , 0 then concatenating both datasets** + **let's shuffle our data and set the seed to ensure reproducibility**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8637f4a",
      "metadata": {
        "papermill": {
          "duration": 0.123952,
          "end_time": "2024-03-31T17:35:05.575980",
          "exception": false,
          "start_time": "2024-03-31T17:35:05.452028",
          "status": "completed"
        },
        "tags": [],
        "id": "b8637f4a"
      },
      "outputs": [],
      "source": [
        "real['target']=1\n",
        "fake['target']=0\n",
        "\n",
        "data = pd.concat([real , fake] , ignore_index=True)\n",
        "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "\n",
        "display(data.head())\n",
        "print('-'*40)\n",
        "\n",
        "print('shape' , data.shape)\n",
        "print('-'*40)\n",
        "\n",
        "display(data.dtypes )\n",
        "print('-'*40)\n",
        "\n",
        "display(data.isna().sum())\n",
        "print('\\n we have no null values ' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13695da6",
      "metadata": {
        "papermill": {
          "duration": 0.037731,
          "end_time": "2024-03-31T17:35:05.629414",
          "exception": false,
          "start_time": "2024-03-31T17:35:05.591683",
          "status": "completed"
        },
        "tags": [],
        "id": "13695da6"
      },
      "outputs": [],
      "source": [
        "data.target.value_counts(normalize=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9836816",
      "metadata": {
        "papermill": {
          "duration": 0.016169,
          "end_time": "2024-03-31T17:35:05.661564",
          "exception": false,
          "start_time": "2024-03-31T17:35:05.645395",
          "status": "completed"
        },
        "tags": [],
        "id": "e9836816"
      },
      "source": [
        "**-------------------------------------->**\n",
        "Here its just to have an estimate on what od the subjects have more fake news **rs1** , and which of them have real news **rs2**\n",
        "to see if to keep the column or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "550affc7",
      "metadata": {
        "papermill": {
          "duration": 0.047205,
          "end_time": "2024-03-31T17:35:05.725301",
          "exception": false,
          "start_time": "2024-03-31T17:35:05.678096",
          "status": "completed"
        },
        "tags": [],
        "id": "550affc7"
      },
      "outputs": [],
      "source": [
        "rs1 = data[data['target'] == 0].groupby(['subject'], as_index=False).size()\n",
        "rs1 = rs1.rename(columns={'size': 'count'}).sort_values(by='count', ascending=False)\n",
        "print(rs1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d87e453",
      "metadata": {
        "papermill": {
          "duration": 0.040142,
          "end_time": "2024-03-31T17:35:05.782918",
          "exception": false,
          "start_time": "2024-03-31T17:35:05.742776",
          "status": "completed"
        },
        "tags": [],
        "id": "1d87e453"
      },
      "outputs": [],
      "source": [
        "rs2 = data[data['target'] == 1].groupby(['subject'], as_index=False).size()\n",
        "rs2 = rs2.rename(columns={'size': 'count'}).sort_values(by='count', ascending=False)\n",
        "print(rs2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c06ddae",
      "metadata": {
        "papermill": {
          "duration": 0.444833,
          "end_time": "2024-03-31T17:35:06.243245",
          "exception": false,
          "start_time": "2024-03-31T17:35:05.798412",
          "status": "completed"
        },
        "tags": [],
        "id": "0c06ddae"
      },
      "outputs": [],
      "source": [
        "subject_distribution = data.groupby(['subject', 'target']).size().unstack(fill_value=0)\n",
        "\n",
        "# Plotting the bar chart using Matplotlib\n",
        "subject_distribution.plot(kind='bar', stacked=True)\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Subject')\n",
        "plt.ylabel('Number of Articles')\n",
        "plt.title('Distribution of Subjects Between True and Fake News')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1f50b74",
      "metadata": {
        "papermill": {
          "duration": 0.015713,
          "end_time": "2024-03-31T17:35:06.275313",
          "exception": false,
          "start_time": "2024-03-31T17:35:06.259600",
          "status": "completed"
        },
        "tags": [],
        "id": "b1f50b74"
      },
      "source": [
        "**--------------------->**\n",
        "clear\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71581780",
      "metadata": {
        "papermill": {
          "duration": 0.661849,
          "end_time": "2024-03-31T17:35:06.953579",
          "exception": false,
          "start_time": "2024-03-31T17:35:06.291730",
          "status": "completed"
        },
        "tags": [],
        "id": "71581780"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"whitegrid\") # Set style for chart\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.pie(data['subject'].value_counts(),labels=data['subject'].value_counts().index.tolist(), autopct='%1.1f%%')\n",
        "plt.title('percentage of our subjects')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eea27f5b",
      "metadata": {
        "papermill": {
          "duration": 0.041674,
          "end_time": "2024-03-31T17:35:07.012444",
          "exception": false,
          "start_time": "2024-03-31T17:35:06.970770",
          "status": "completed"
        },
        "tags": [],
        "id": "eea27f5b"
      },
      "outputs": [],
      "source": [
        "data.subject=data.subject.replace({'politics':'PoliticsNews','politicsNews':'PoliticsNews'})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0da73d4c",
      "metadata": {
        "papermill": {
          "duration": 0.271294,
          "end_time": "2024-03-31T17:35:07.300520",
          "exception": false,
          "start_time": "2024-03-31T17:35:07.029226",
          "status": "completed"
        },
        "tags": [],
        "id": "0da73d4c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"whitegrid\") # Set style for chart\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.pie(data['subject'].value_counts(),labels=data['subject'].value_counts().index.tolist(), autopct='%1.1f%%')\n",
        "plt.title('percentage of our subjects')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3282e7e2",
      "metadata": {
        "papermill": {
          "duration": 0.434338,
          "end_time": "2024-03-31T17:35:07.753074",
          "exception": false,
          "start_time": "2024-03-31T17:35:07.318736",
          "status": "completed"
        },
        "tags": [],
        "id": "3282e7e2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Count the number of articles for each subject\n",
        "subject_counts = data['subject'].value_counts()\n",
        "\n",
        "# Get the top subjects with the most news coverage\n",
        "top_subjects = subject_counts.head(10)  # Adjust the number as needed\n",
        "\n",
        "# Plot the distribution of subjects\n",
        "top_subjects.plot(kind='bar', figsize=(10, 6), color='skyblue')\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Top Subjects with the Most News Coverage')\n",
        "plt.xlabel('Subject')\n",
        "plt.ylabel('Number of Articles')\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48287766",
      "metadata": {
        "papermill": {
          "duration": 0.018934,
          "end_time": "2024-03-31T17:35:07.790958",
          "exception": false,
          "start_time": "2024-03-31T17:35:07.772024",
          "status": "completed"
        },
        "tags": [],
        "id": "48287766"
      },
      "source": [
        "Here im calculating the information gain of each feature to see what to keep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8da10c5",
      "metadata": {
        "papermill": {
          "duration": 0.029911,
          "end_time": "2024-03-31T17:35:07.840194",
          "exception": false,
          "start_time": "2024-03-31T17:35:07.810283",
          "status": "completed"
        },
        "tags": [],
        "id": "c8da10c5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "# # Assuming 'data' is your DataFrame with the specified data types\n",
        "\n",
        "# # Step 1: Tokenize and vectorize text data (title and text columns)\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "title_text_features = tfidf_vectorizer.fit_transform(data['title'] + ' ' + data['text'])\n",
        "\n",
        "# # Step 2: Encode categorical variables (subject column)\n",
        "data_encoded = pd.get_dummies(data, columns=['subject'])\n",
        "\n",
        "# # Step 3: Extract features from date column if needed\n",
        "\n",
        "# # Step 4: Combine features for information gain calculation\n",
        "X = pd.concat([data_encoded.drop(columns=['title', 'text', 'date', 'target']), pd.DataFrame(title_text_features.toarray())], axis=1)\n",
        "y = data['target']\n",
        "\n",
        "# # Step 5: Calculate information gain for each feature\n",
        "info_gain = mutual_info_classif(X, y)\n",
        "\n",
        "# # Create a DataFrame to show the information gain for each feature\n",
        "info_gain_df = pd.DataFrame({'Feature': X.columns, 'Information Gain': info_gain})\n",
        "info_gain_df.sort_values(by='Information Gain', ascending=False, inplace=True)\n",
        "\n",
        "print(info_gain_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15d795a9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-31T17:35:07.880333Z",
          "iopub.status.busy": "2024-03-31T17:35:07.879866Z",
          "iopub.status.idle": "2024-03-31T17:35:07.885008Z",
          "shell.execute_reply": "2024-03-31T17:35:07.883650Z"
        },
        "papermill": {
          "duration": 0.028598,
          "end_time": "2024-03-31T17:35:07.887555",
          "exception": false,
          "start_time": "2024-03-31T17:35:07.858957",
          "status": "completed"
        },
        "tags": [],
        "id": "15d795a9"
      },
      "outputs": [],
      "source": [
        "X[3841]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f526c8cf",
      "metadata": {
        "papermill": {
          "duration": 0.019186,
          "end_time": "2024-03-31T17:35:07.925518",
          "exception": false,
          "start_time": "2024-03-31T17:35:07.906332",
          "status": "completed"
        },
        "tags": [],
        "id": "f526c8cf"
      },
      "source": [
        "\n",
        "1. **Feature: 3841, Information Gain: 0.655321**\n",
        "   - This feature, represented by index 3833, has a high information gain value of approximately 0.655. It indicates that this particular feature (which could be a numerical feature or an encoded categorical feature) is highly informative or predictive of the target variable. Its presence or value strongly influences the prediction of the target variable.\n",
        "\n",
        "2. **Feature: 3935, Information Gain: 0.259228**\n",
        "   - The feature represented by index 3927 has an information gain value of approximately 0.259. While not as high as the first feature, this feature still contributes significantly to predicting the target variable. It provides valuable information for making predictions but may not be as influential as the feature with higher information gain.\n",
        "\n",
        "3. **Feature: subject_politicsNews, Information Gain: 0.237904**\n",
        "   - This feature corresponds to the subject category \"politicsNews\" in your dataset, which is one of the subjects. Its information gain value of approximately 0.238 indicates that this subject category is moderately informative or predictive of the target variable. Articles or data points related to politicsNews have some influence on predicting the target variable.\n",
        "\n",
        "4. **Feature: subject_worldnews, Information Gain: 0.208071**\n",
        "   - Similarly, this feature corresponds to the subject category \"worldnews\" with an information gain value of approximately 0.208. It suggests that articles or data points related to world news also contribute to predicting the target variable, although to a slightly lesser extent compared to the politicsNews category.\n",
        "\n",
        "5. **Features with Information Gain of 0.000**\n",
        "   - Rows with features that have an information gain value of 0.000 indicate that these features provide no information or very little information for predicting the target variable. They do not contribute significantly to the prediction process based on the information gain calculation.\n",
        "\n",
        "Overall, the information gain values help prioritize features based on their importance and relevance in predicting the target variable. Features with higher information gain values are more influential in prediction tasks, while features with lower or zero information gain values may be less relevant for prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36126921",
      "metadata": {
        "papermill": {
          "duration": 0.019003,
          "end_time": "2024-03-31T17:35:07.963935",
          "exception": false,
          "start_time": "2024-03-31T17:35:07.944932",
          "status": "completed"
        },
        "tags": [],
        "id": "36126921"
      },
      "source": [
        "### *I will add subject to the model as one of the subject features has high info gain*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cf1fa4a",
      "metadata": {
        "papermill": {
          "duration": 0.01922,
          "end_time": "2024-03-31T17:35:08.002286",
          "exception": false,
          "start_time": "2024-03-31T17:35:07.983066",
          "status": "completed"
        },
        "tags": [],
        "id": "7cf1fa4a"
      },
      "source": [
        "***\n",
        "<div style=\"text-align:center;\">\n",
        "    <span style=\"font-size:29px; color:green;\">Text pre-processing</span>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b332162",
      "metadata": {
        "papermill": {
          "duration": 0.019279,
          "end_time": "2024-03-31T17:35:08.040583",
          "exception": false,
          "start_time": "2024-03-31T17:35:08.021304",
          "status": "completed"
        },
        "tags": [],
        "id": "0b332162"
      },
      "source": [
        "![Screenshot (188).png](attachment:84463305-fec6-4c62-a2c7-2792a788c0f6.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82b7a3e0",
      "metadata": {
        "papermill": {
          "duration": 0.062222,
          "end_time": "2024-03-31T17:35:08.123224",
          "exception": false,
          "start_time": "2024-03-31T17:35:08.061002",
          "status": "completed"
        },
        "tags": [],
        "id": "82b7a3e0"
      },
      "outputs": [],
      "source": [
        "data['final'] =  data['title'] + \" \" + data['subject']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbce9cb6",
      "metadata": {
        "papermill": {
          "duration": 0.0357,
          "end_time": "2024-03-31T17:35:08.177613",
          "exception": false,
          "start_time": "2024-03-31T17:35:08.141913",
          "status": "completed"
        },
        "tags": [],
        "id": "cbce9cb6"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "\n",
        "# Download the stopwords corpus if it's not already downloaded\n",
        "try:\n",
        "    nltk.download('stopwords')\n",
        "except Exception as e:\n",
        "    print(\"Stopwords corpus already downloaded.\")\n",
        "\n",
        "# Load the stopwords\n",
        "stop = set(stopwords.words('english'))\n",
        "\n",
        "# Add punctuation to the stopwords set\n",
        "pnc = list(punctuation)\n",
        "stop.update(pnc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "261d29df",
      "metadata": {
        "papermill": {
          "duration": 0.030034,
          "end_time": "2024-03-31T17:35:08.226417",
          "exception": false,
          "start_time": "2024-03-31T17:35:08.196383",
          "status": "completed"
        },
        "tags": [],
        "id": "261d29df"
      },
      "outputs": [],
      "source": [
        "stemmer = PorterStemmer()\n",
        "def stem_text(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in stop:\n",
        "            word = stemmer.stem(i.strip())\n",
        "            final_text.append(word)\n",
        "    return \" \".join(final_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d72c5964",
      "metadata": {
        "papermill": {
          "duration": 19.001232,
          "end_time": "2024-03-31T17:35:27.246290",
          "exception": false,
          "start_time": "2024-03-31T17:35:08.245058",
          "status": "completed"
        },
        "tags": [],
        "id": "d72c5964"
      },
      "outputs": [],
      "source": [
        "data['final'] = data['final'].apply(stem_text)\n",
        "data['final'].head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de474bcb",
      "metadata": {
        "papermill": {
          "duration": 2.519021,
          "end_time": "2024-03-31T17:35:29.784136",
          "exception": false,
          "start_time": "2024-03-31T17:35:27.265115",
          "status": "completed"
        },
        "tags": [],
        "id": "de474bcb"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "X_train,X_test,y_train,y_test = train_test_split(data['final'],data['target'])\n",
        "cv = CountVectorizer(min_df=0,max_df=1,ngram_range=(1,2))\n",
        "\n",
        "cv_train = cv.fit_transform(X_train)\n",
        "cv_test = cv.transform(X_test)\n",
        "\n",
        "print('Train shape: ',cv_train.shape)\n",
        "print('Test shape: ',cv_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b7fc14e",
      "metadata": {
        "papermill": {
          "duration": 0.058714,
          "end_time": "2024-03-31T17:35:29.862954",
          "exception": false,
          "start_time": "2024-03-31T17:35:29.804240",
          "status": "completed"
        },
        "tags": [],
        "id": "4b7fc14e"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "nb = MultinomialNB()\n",
        "nb.fit(cv_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f0d885a",
      "metadata": {
        "papermill": {
          "duration": 0.036024,
          "end_time": "2024-03-31T17:35:29.918138",
          "exception": false,
          "start_time": "2024-03-31T17:35:29.882114",
          "status": "completed"
        },
        "tags": [],
        "id": "1f0d885a"
      },
      "outputs": [],
      "source": [
        "pred_nb = nb.predict(cv_test)\n",
        "score = accuracy_score(y_test, pred_nb)\n",
        "print(\"Accuracy Score: \",score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34f90e5b",
      "metadata": {
        "papermill": {
          "duration": 0.019658,
          "end_time": "2024-03-31T17:35:29.957298",
          "exception": false,
          "start_time": "2024-03-31T17:35:29.937640",
          "status": "completed"
        },
        "tags": [],
        "id": "34f90e5b"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "590c022d",
      "metadata": {
        "papermill": {
          "duration": 451.809534,
          "end_time": "2024-03-31T17:43:01.786416",
          "exception": false,
          "start_time": "2024-03-31T17:35:29.976882",
          "status": "completed"
        },
        "tags": [],
        "id": "590c022d"
      },
      "outputs": [],
      "source": [
        "data['final2'] =  data['text'] + \" \" + data['title'] + \" \" + data['subject']\n",
        "data['final2'] = data['final2'].apply(stem_text)\n",
        "data['final2'].head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63ead1e7",
      "metadata": {
        "papermill": {
          "duration": 54.907964,
          "end_time": "2024-03-31T17:43:56.713978",
          "exception": false,
          "start_time": "2024-03-31T17:43:01.806014",
          "status": "completed"
        },
        "tags": [],
        "id": "63ead1e7"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(data['final2'],data['target'])\n",
        "cv = CountVectorizer(min_df=0,max_df=1,ngram_range=(1,2))\n",
        "\n",
        "cv_train = cv.fit_transform(X_train)\n",
        "cv_test = cv.transform(X_test)\n",
        "\n",
        "print('Train shape: ',cv_train.shape)\n",
        "print('Test shape: ',cv_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "nb = MultinomialNB()\n",
        "nb.fit(cv_train, y_train)\n",
        "\n",
        "pred_nb = nb.predict(cv_test)\n",
        "score = accuracy_score(y_test, pred_nb)\n",
        "print(\"Accuracy Score: \",score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c796da65-de75-4199-926f-33bb7822bb73",
      "metadata": {
        "id": "c796da65-de75-4199-926f-33bb7822bb73"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 2712039,
          "sourceId": 4679796,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30673,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 543.970066,
      "end_time": "2024-03-31T17:43:58.366540",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-03-31T17:34:54.396474",
      "version": "2.5.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}